# Model Architecture

The **BlurProof** model uses a deep convolutional neural network based on the **U-Net** architecture.
It learns to reconstruct clean astronomical images from simulated dirty inputs by inverting the convolution introduced by the telescope’s point spread function (PSF).

---

## Overview

Each dirty image ( I_{dirty} ) is generated by convolving a clean image ( I_{true} ) with a PSF ( B_{dirty} ):

[
I_{dirty} = I_{true} * B_{dirty}
]

The network learns to approximate the inverse mapping:

[
I_{clean} \approx f_\theta(I_{dirty})
]

where ( f_\theta ) represents the U-Net with parameters ( \theta ).

---

## U-Net256

The implemented network, `UNet256`, is a compact variant of the standard U-Net architecture optimized for 256×256 grayscale images.

### Encoder

The encoder progressively downsamples the input while increasing feature depth:

* Four convolutional blocks with Batch Normalization and ReLU
* Each block doubles the number of filters
* Max pooling with stride 2 for spatial reduction

### Bottleneck

The deepest layer (bottleneck) captures high-level abstract features using two convolutional layers with 1024 filters.

### Decoder

The decoder mirrors the encoder, restoring spatial resolution:

* Transposed convolution for upsampling
* Skip connections concatenate encoder features
* Each block halves the number of filters
* Final 1×1 convolution maps features to a single output channel

### Activation

A **sigmoid** activation ensures outputs remain within [0, 1].

---

## Loss and Metrics

The model is trained using **mean squared error (MSE)** between the predicted and target images:

[
\mathcal{L}*{MSE} = \frac{1}{N} \sum (I*{pred} - I_{true})^2
]

During training, two perceptual metrics are also computed:

* **PSNR (Peak Signal-to-Noise Ratio)** — measures reconstruction quality.
* **SSIM (Structural Similarity Index)** — measures perceived image similarity.

---

## Implementation Details

* Framework: **PyTorch**
* Input/Output size: 1 × 256 × 256
* Optimizer: **Adam**, learning rate = 1e−3
* Loss: **MSELoss**
* Normalization: BatchNorm2d
* Activation: ReLU + Sigmoid

---

## Next Steps

The current architecture, data pipeline, and PSF generation are fully implemented.
However, the model has **not been trained yet** — all preprocessing and scripts are ready for training.

Future plans include:

* Adding larger U-Net variants and residual architectures.
* Experimenting with perceptual and adversarial losses.
* Evaluating generalization across telescope configurations.

